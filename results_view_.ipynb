{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5227c624-fc27-4f4c-a927-7a73a0758f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86b30f91-9bdc-4460-879d-b89cdcbce2c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuebing/.conda/envs/controlnet_hemy/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logging improved.\n"
     ]
    }
   ],
   "source": [
    "from share import *\n",
    "import config\n",
    "\n",
    "import cv2\n",
    "import einops\n",
    "#import gradio as gr\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "\n",
    "from pytorch_lightning import seed_everything\n",
    "from annotator.util import resize_image, HWC3\n",
    "from annotator.hed import HEDdetector\n",
    "from cldm.model import create_model, load_state_dict\n",
    "from cldm.ddim_hacked import DDIMSampler\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb4d033d-2a74-4648-8bab-6d1039b04111",
   "metadata": {},
   "outputs": [],
   "source": [
    "from decimal import Decimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cffae1ac-dadd-403e-b99d-d57bfdae7ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of available GPUs: 7\n"
     ]
    }
   ],
   "source": [
    "# 打印可用 GPU 的数量\n",
    "num_gpus = torch.cuda.device_count()\n",
    "print(f\"Number of available GPUs: {num_gpus}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c26bc4d-5cbf-415b-bb5c-545a7f7ea4f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9dd95a8-e8cf-4cd1-8949-dbde63078475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:2\n",
      "Using device: NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:2')\n",
    "print(device)  # 输出：device(type='cuda', index=1)\n",
    "torch.cuda.set_device(device)\n",
    "# 检查设备是否正确设置\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Using device: {torch.cuda.get_device_name(device)}\")\n",
    "else:\n",
    "    print(\"CUDA is not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffc4d9db-767d-47e0-9057-141c3b1ae129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently using GPU: 2\n",
      "GPU name: NVIDIA GeForce RTX 3090\n",
      "Total memory: 25430786048\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(f\"Currently using GPU: {torch.cuda.current_device()}\")\n",
    "    print(f\"GPU name: {torch.cuda.get_device_name(torch.cuda.current_device())}\")\n",
    "    print(f\"Total memory: {torch.cuda.get_device_properties(torch.cuda.current_device()).total_memory}\")\n",
    "else:\n",
    "    print(\"No GPU is being used.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe161077-c3f4-4aa6-9c1f-cc5d30151f68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddd77236-ec1e-4671-bc0d-065432440e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "version = '24511719'\n",
    "epoch = '4'\n",
    "step = '112594'\n",
    "city_dic={'chicago': 'Chicago', 'dallas':'Dallas', 'la':'Los Angeles'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce80482d-f8b2-41ee-8317-7ef0400deb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "version = '0'\n",
    "epoch = '1'\n",
    "step = '20397'\n",
    "city_dic={'chicago': 'Chicago', 'dallas':'Dallas', 'la':'Los Angeles'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0347e95a-1935-43d6-94fc-f289318ae60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "version = '0'\n",
    "epoch = '4'\n",
    "step = '50994'\n",
    "city_dic={'chicago': 'Chicago', 'dallas':'Dallas', 'la':'Los Angeles'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5dffb248-be57-4700-8b12-0364f1bfec87",
   "metadata": {},
   "outputs": [],
   "source": [
    "version = '3'\n",
    "epoch = '6'\n",
    "step = '101877'\n",
    "city_dic={'chicago': 'Chicago', 'dallas':'Dallas', 'la':'Los Angeles'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b28ffc7d-7657-4ead-9b6b-000e1ec22eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "version = '3'\n",
    "epoch = '10'\n",
    "step = '160093'\n",
    "city_dic={'chicago': 'Chicago', 'dallas':'Dallas', 'la':'Los Angeles'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f9f7d6f4-2698-4ce3-b42e-0cda935d5dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "version = '3'\n",
    "epoch = '16'\n",
    "step = '247417'\n",
    "city_dic={'chicago': 'Chicago', 'dallas':'Dallas', 'la':'Los Angeles'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6caa74c2-3491-47bc-bffc-d81f8691a236",
   "metadata": {},
   "outputs": [],
   "source": [
    "version = '3'\n",
    "epoch = '24'\n",
    "step = '363849'\n",
    "city_dic={'chicago': 'Chicago', 'dallas':'Dallas', 'la':'Los Angeles'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f78746e-aef5-40c1-97ed-c750deec735d",
   "metadata": {},
   "outputs": [],
   "source": [
    "version = '3'\n",
    "epoch = '29'\n",
    "step = '436619'\n",
    "city_dic={'chicago': 'Chicago', 'dallas':'Dallas', 'la':'Los Angeles'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b3cfb16-f7b9-48e7-944c-b222ca89a298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No module 'xformers'. Proceeding without it.\n",
      "ControlLDM: Running in eps-prediction mode\n",
      "DiffusionWrapper has 859.52 M params.\n",
      "making attention of type 'vanilla' with 512 in_channels\n",
      "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
      "making attention of type 'vanilla' with 512 in_channels\n",
      "Loaded model config from [./models/cldm_v15.yaml]\n"
     ]
    }
   ],
   "source": [
    "model = create_model('./models/cldm_v15.yaml').cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "faea4b6f-fc8c-4f18-8f6a-43fcc20bac0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded state_dict from [./lightning_logs/version_3/checkpoints/epoch=29-step=436619.ckpt]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ControlLDM(\n",
       "  (model): DiffusionWrapper(\n",
       "    (diffusion_model): ControlledUnetModel(\n",
       "      (time_embed): Sequential(\n",
       "        (0): Linear(in_features=320, out_features=1280, bias=True)\n",
       "        (1): SiLU()\n",
       "        (2): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      )\n",
       "      (input_blocks): ModuleList(\n",
       "        (0): TimestepEmbedSequential(\n",
       "          (0): Conv2d(4, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (1): TimestepEmbedSequential(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=320, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Identity()\n",
       "          )\n",
       "          (1): SpatialTransformer(\n",
       "            (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "            (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (transformer_blocks): ModuleList(\n",
       "              (0): BasicTransformerBlock(\n",
       "                (attn1): CrossAttention(\n",
       "                  (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                  (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "                  (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (ff): FeedForward(\n",
       "                  (net): Sequential(\n",
       "                    (0): GEGLU(\n",
       "                      (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                    )\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                    (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (attn2): CrossAttention(\n",
       "                  (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                  (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
       "                  (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (2): TimestepEmbedSequential(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=320, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Identity()\n",
       "          )\n",
       "          (1): SpatialTransformer(\n",
       "            (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "            (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (transformer_blocks): ModuleList(\n",
       "              (0): BasicTransformerBlock(\n",
       "                (attn1): CrossAttention(\n",
       "                  (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                  (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "                  (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (ff): FeedForward(\n",
       "                  (net): Sequential(\n",
       "                    (0): GEGLU(\n",
       "                      (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                    )\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                    (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (attn2): CrossAttention(\n",
       "                  (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                  (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
       "                  (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (3): TimestepEmbedSequential(\n",
       "          (0): Downsample(\n",
       "            (op): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (4): TimestepEmbedSequential(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(320, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=640, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Conv2d(320, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): SpatialTransformer(\n",
       "            (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "            (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (transformer_blocks): ModuleList(\n",
       "              (0): BasicTransformerBlock(\n",
       "                (attn1): CrossAttention(\n",
       "                  (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (ff): FeedForward(\n",
       "                  (net): Sequential(\n",
       "                    (0): GEGLU(\n",
       "                      (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                    )\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                    (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (attn2): CrossAttention(\n",
       "                  (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
       "                  (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (5): TimestepEmbedSequential(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=640, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Identity()\n",
       "          )\n",
       "          (1): SpatialTransformer(\n",
       "            (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "            (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (transformer_blocks): ModuleList(\n",
       "              (0): BasicTransformerBlock(\n",
       "                (attn1): CrossAttention(\n",
       "                  (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (ff): FeedForward(\n",
       "                  (net): Sequential(\n",
       "                    (0): GEGLU(\n",
       "                      (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                    )\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                    (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (attn2): CrossAttention(\n",
       "                  (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
       "                  (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (6): TimestepEmbedSequential(\n",
       "          (0): Downsample(\n",
       "            (op): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (7): TimestepEmbedSequential(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(640, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Conv2d(640, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): SpatialTransformer(\n",
       "            (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "            (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (transformer_blocks): ModuleList(\n",
       "              (0): BasicTransformerBlock(\n",
       "                (attn1): CrossAttention(\n",
       "                  (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (ff): FeedForward(\n",
       "                  (net): Sequential(\n",
       "                    (0): GEGLU(\n",
       "                      (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                    )\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                    (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (attn2): CrossAttention(\n",
       "                  (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                  (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (8): TimestepEmbedSequential(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Identity()\n",
       "          )\n",
       "          (1): SpatialTransformer(\n",
       "            (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "            (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (transformer_blocks): ModuleList(\n",
       "              (0): BasicTransformerBlock(\n",
       "                (attn1): CrossAttention(\n",
       "                  (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (ff): FeedForward(\n",
       "                  (net): Sequential(\n",
       "                    (0): GEGLU(\n",
       "                      (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                    )\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                    (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (attn2): CrossAttention(\n",
       "                  (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                  (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (9): TimestepEmbedSequential(\n",
       "          (0): Downsample(\n",
       "            (op): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (10): TimestepEmbedSequential(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Identity()\n",
       "          )\n",
       "        )\n",
       "        (11): TimestepEmbedSequential(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (middle_block): TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Identity()\n",
       "        )\n",
       "        (1): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Identity()\n",
       "        )\n",
       "      )\n",
       "      (output_blocks): ModuleList(\n",
       "        (0): TimestepEmbedSequential(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (1): TimestepEmbedSequential(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (2): TimestepEmbedSequential(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): Upsample(\n",
       "            (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (3): TimestepEmbedSequential(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): SpatialTransformer(\n",
       "            (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "            (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (transformer_blocks): ModuleList(\n",
       "              (0): BasicTransformerBlock(\n",
       "                (attn1): CrossAttention(\n",
       "                  (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (ff): FeedForward(\n",
       "                  (net): Sequential(\n",
       "                    (0): GEGLU(\n",
       "                      (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                    )\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                    (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (attn2): CrossAttention(\n",
       "                  (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                  (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (4): TimestepEmbedSequential(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): SpatialTransformer(\n",
       "            (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "            (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (transformer_blocks): ModuleList(\n",
       "              (0): BasicTransformerBlock(\n",
       "                (attn1): CrossAttention(\n",
       "                  (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (ff): FeedForward(\n",
       "                  (net): Sequential(\n",
       "                    (0): GEGLU(\n",
       "                      (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                    )\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                    (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (attn2): CrossAttention(\n",
       "                  (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                  (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (5): TimestepEmbedSequential(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1920, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(1920, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Conv2d(1920, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): SpatialTransformer(\n",
       "            (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "            (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (transformer_blocks): ModuleList(\n",
       "              (0): BasicTransformerBlock(\n",
       "                (attn1): CrossAttention(\n",
       "                  (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (ff): FeedForward(\n",
       "                  (net): Sequential(\n",
       "                    (0): GEGLU(\n",
       "                      (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                    )\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                    (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (attn2): CrossAttention(\n",
       "                  (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                  (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (2): Upsample(\n",
       "            (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (6): TimestepEmbedSequential(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1920, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(1920, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=640, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Conv2d(1920, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): SpatialTransformer(\n",
       "            (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "            (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (transformer_blocks): ModuleList(\n",
       "              (0): BasicTransformerBlock(\n",
       "                (attn1): CrossAttention(\n",
       "                  (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (ff): FeedForward(\n",
       "                  (net): Sequential(\n",
       "                    (0): GEGLU(\n",
       "                      (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                    )\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                    (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (attn2): CrossAttention(\n",
       "                  (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
       "                  (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (7): TimestepEmbedSequential(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(1280, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=640, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): SpatialTransformer(\n",
       "            (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "            (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (transformer_blocks): ModuleList(\n",
       "              (0): BasicTransformerBlock(\n",
       "                (attn1): CrossAttention(\n",
       "                  (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (ff): FeedForward(\n",
       "                  (net): Sequential(\n",
       "                    (0): GEGLU(\n",
       "                      (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                    )\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                    (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (attn2): CrossAttention(\n",
       "                  (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
       "                  (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (8): TimestepEmbedSequential(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 960, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(960, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=640, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Conv2d(960, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): SpatialTransformer(\n",
       "            (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "            (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (transformer_blocks): ModuleList(\n",
       "              (0): BasicTransformerBlock(\n",
       "                (attn1): CrossAttention(\n",
       "                  (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (ff): FeedForward(\n",
       "                  (net): Sequential(\n",
       "                    (0): GEGLU(\n",
       "                      (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                    )\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                    (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (attn2): CrossAttention(\n",
       "                  (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
       "                  (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (2): Upsample(\n",
       "            (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (9): TimestepEmbedSequential(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 960, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(960, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=320, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): SpatialTransformer(\n",
       "            (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "            (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (transformer_blocks): ModuleList(\n",
       "              (0): BasicTransformerBlock(\n",
       "                (attn1): CrossAttention(\n",
       "                  (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                  (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "                  (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (ff): FeedForward(\n",
       "                  (net): Sequential(\n",
       "                    (0): GEGLU(\n",
       "                      (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                    )\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                    (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (attn2): CrossAttention(\n",
       "                  (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                  (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
       "                  (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (10): TimestepEmbedSequential(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=320, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): SpatialTransformer(\n",
       "            (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "            (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (transformer_blocks): ModuleList(\n",
       "              (0): BasicTransformerBlock(\n",
       "                (attn1): CrossAttention(\n",
       "                  (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                  (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "                  (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (ff): FeedForward(\n",
       "                  (net): Sequential(\n",
       "                    (0): GEGLU(\n",
       "                      (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                    )\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                    (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (attn2): CrossAttention(\n",
       "                  (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                  (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
       "                  (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (11): TimestepEmbedSequential(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=320, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): SpatialTransformer(\n",
       "            (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "            (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (transformer_blocks): ModuleList(\n",
       "              (0): BasicTransformerBlock(\n",
       "                (attn1): CrossAttention(\n",
       "                  (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                  (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "                  (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (ff): FeedForward(\n",
       "                  (net): Sequential(\n",
       "                    (0): GEGLU(\n",
       "                      (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                    )\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                    (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (attn2): CrossAttention(\n",
       "                  (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                  (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
       "                  (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (out): Sequential(\n",
       "        (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Conv2d(320, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (first_stage_model): AutoencoderKL(\n",
       "    (encoder): Encoder(\n",
       "      (conv_in): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (down): ModuleList(\n",
       "        (0): Module(\n",
       "          (block): ModuleList(\n",
       "            (0): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (1): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (attn): ModuleList()\n",
       "          (downsample): Downsample(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2))\n",
       "          )\n",
       "        )\n",
       "        (1): Module(\n",
       "          (block): ModuleList(\n",
       "            (0): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (nin_shortcut): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (1): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (attn): ModuleList()\n",
       "          (downsample): Downsample(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))\n",
       "          )\n",
       "        )\n",
       "        (2): Module(\n",
       "          (block): ModuleList(\n",
       "            (0): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (nin_shortcut): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (1): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (attn): ModuleList()\n",
       "          (downsample): Downsample(\n",
       "            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2))\n",
       "          )\n",
       "        )\n",
       "        (3): Module(\n",
       "          (block): ModuleList(\n",
       "            (0): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (1): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (attn): ModuleList()\n",
       "        )\n",
       "      )\n",
       "      (mid): Module(\n",
       "        (block_1): ResnetBlock(\n",
       "          (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (attn_1): AttnBlock(\n",
       "          (norm): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (q): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (k): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (v): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (proj_out): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (block_2): ResnetBlock(\n",
       "          (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (norm_out): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "      (conv_out): Conv2d(512, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (decoder): Decoder(\n",
       "      (conv_in): Conv2d(4, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (mid): Module(\n",
       "        (block_1): ResnetBlock(\n",
       "          (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (attn_1): AttnBlock(\n",
       "          (norm): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (q): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (k): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (v): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (proj_out): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (block_2): ResnetBlock(\n",
       "          (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (up): ModuleList(\n",
       "        (0): Module(\n",
       "          (block): ModuleList(\n",
       "            (0): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (nin_shortcut): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (1): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (2): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (attn): ModuleList()\n",
       "        )\n",
       "        (1): Module(\n",
       "          (block): ModuleList(\n",
       "            (0): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (nin_shortcut): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (1): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (2): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (attn): ModuleList()\n",
       "          (upsample): Upsample(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (2): Module(\n",
       "          (block): ModuleList(\n",
       "            (0): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (1): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (2): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (attn): ModuleList()\n",
       "          (upsample): Upsample(\n",
       "            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (3): Module(\n",
       "          (block): ModuleList(\n",
       "            (0): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (1): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (2): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (attn): ModuleList()\n",
       "          (upsample): Upsample(\n",
       "            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm_out): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "      (conv_out): Conv2d(128, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (loss): Identity()\n",
       "    (quant_conv): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (post_quant_conv): Conv2d(4, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (cond_stage_model): FrozenCLIPEmbedder(\n",
       "    (transformer): CLIPTextModel(\n",
       "      (text_model): CLIPTextTransformer(\n",
       "        (embeddings): CLIPTextEmbeddings(\n",
       "          (token_embedding): Embedding(49408, 768)\n",
       "          (position_embedding): Embedding(77, 768)\n",
       "        )\n",
       "        (encoder): CLIPEncoder(\n",
       "          (layers): ModuleList(\n",
       "            (0): CLIPEncoderLayer(\n",
       "              (self_attn): CLIPAttention(\n",
       "                (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): CLIPMLP(\n",
       "                (activation_fn): QuickGELUActivation()\n",
       "                (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              )\n",
       "              (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (1): CLIPEncoderLayer(\n",
       "              (self_attn): CLIPAttention(\n",
       "                (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): CLIPMLP(\n",
       "                (activation_fn): QuickGELUActivation()\n",
       "                (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              )\n",
       "              (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (2): CLIPEncoderLayer(\n",
       "              (self_attn): CLIPAttention(\n",
       "                (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): CLIPMLP(\n",
       "                (activation_fn): QuickGELUActivation()\n",
       "                (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              )\n",
       "              (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (3): CLIPEncoderLayer(\n",
       "              (self_attn): CLIPAttention(\n",
       "                (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): CLIPMLP(\n",
       "                (activation_fn): QuickGELUActivation()\n",
       "                (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              )\n",
       "              (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (4): CLIPEncoderLayer(\n",
       "              (self_attn): CLIPAttention(\n",
       "                (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): CLIPMLP(\n",
       "                (activation_fn): QuickGELUActivation()\n",
       "                (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              )\n",
       "              (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (5): CLIPEncoderLayer(\n",
       "              (self_attn): CLIPAttention(\n",
       "                (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): CLIPMLP(\n",
       "                (activation_fn): QuickGELUActivation()\n",
       "                (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              )\n",
       "              (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (6): CLIPEncoderLayer(\n",
       "              (self_attn): CLIPAttention(\n",
       "                (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): CLIPMLP(\n",
       "                (activation_fn): QuickGELUActivation()\n",
       "                (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              )\n",
       "              (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (7): CLIPEncoderLayer(\n",
       "              (self_attn): CLIPAttention(\n",
       "                (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): CLIPMLP(\n",
       "                (activation_fn): QuickGELUActivation()\n",
       "                (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              )\n",
       "              (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (8): CLIPEncoderLayer(\n",
       "              (self_attn): CLIPAttention(\n",
       "                (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): CLIPMLP(\n",
       "                (activation_fn): QuickGELUActivation()\n",
       "                (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              )\n",
       "              (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (9): CLIPEncoderLayer(\n",
       "              (self_attn): CLIPAttention(\n",
       "                (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): CLIPMLP(\n",
       "                (activation_fn): QuickGELUActivation()\n",
       "                (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              )\n",
       "              (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (10): CLIPEncoderLayer(\n",
       "              (self_attn): CLIPAttention(\n",
       "                (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): CLIPMLP(\n",
       "                (activation_fn): QuickGELUActivation()\n",
       "                (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              )\n",
       "              (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (11): CLIPEncoderLayer(\n",
       "              (self_attn): CLIPAttention(\n",
       "                (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): CLIPMLP(\n",
       "                (activation_fn): QuickGELUActivation()\n",
       "                (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              )\n",
       "              (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (control_model): ControlNet(\n",
       "    (time_embed): Sequential(\n",
       "      (0): Linear(in_features=320, out_features=1280, bias=True)\n",
       "      (1): SiLU()\n",
       "      (2): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "    )\n",
       "    (input_blocks): ModuleList(\n",
       "      (0): TimestepEmbedSequential(\n",
       "        (0): Conv2d(4, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (1): TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Identity()\n",
       "        )\n",
       "        (1): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (2): TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Identity()\n",
       "        )\n",
       "        (1): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (3): TimestepEmbedSequential(\n",
       "        (0): Downsample(\n",
       "          (op): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (4): TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(320, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=1280, out_features=640, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(320, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (5): TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=1280, out_features=640, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Identity()\n",
       "        )\n",
       "        (1): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (6): TimestepEmbedSequential(\n",
       "        (0): Downsample(\n",
       "          (op): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (7): TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(640, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(640, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (8): TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Identity()\n",
       "        )\n",
       "        (1): SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): CrossAttention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): CrossAttention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (9): TimestepEmbedSequential(\n",
       "        (0): Downsample(\n",
       "          (op): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (10): TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Identity()\n",
       "        )\n",
       "      )\n",
       "      (11): TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (zero_convs): ModuleList(\n",
       "      (0): TimestepEmbedSequential(\n",
       "        (0): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): TimestepEmbedSequential(\n",
       "        (0): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (2): TimestepEmbedSequential(\n",
       "        (0): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (3): TimestepEmbedSequential(\n",
       "        (0): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (4): TimestepEmbedSequential(\n",
       "        (0): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (5): TimestepEmbedSequential(\n",
       "        (0): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (6): TimestepEmbedSequential(\n",
       "        (0): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (7): TimestepEmbedSequential(\n",
       "        (0): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (8): TimestepEmbedSequential(\n",
       "        (0): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (9): TimestepEmbedSequential(\n",
       "        (0): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (10): TimestepEmbedSequential(\n",
       "        (0): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (11): TimestepEmbedSequential(\n",
       "        (0): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (input_hint_block): TimestepEmbedSequential(\n",
       "      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): SiLU()\n",
       "      (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): SiLU()\n",
       "      (4): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (5): SiLU()\n",
       "      (6): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (7): SiLU()\n",
       "      (8): Conv2d(32, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (9): SiLU()\n",
       "      (10): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): SiLU()\n",
       "      (12): Conv2d(96, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (13): SiLU()\n",
       "      (14): Conv2d(256, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (middle_block): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (2): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "    )\n",
       "    (middle_block_out): TimestepEmbedSequential(\n",
       "      (0): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# model.load_state_dict(load_state_dict('./models/control_sd15_ini.ckpt', location='cuda'))\n",
    "# model.load_state_dict(load_state_dict('./lightning_logs/version_23691853/checkpoints/epoch=8-step=74483.ckpt', location='cuda'))\n",
    "# model.load_state_dict(load_state_dict('./lightning_logs/version_23745120/checkpoints/epoch=2-step=24494.ckpt', location='cuda:1'))\n",
    "# model.load_state_dict(load_state_dict('./lightning_logs/version_23786778/checkpoints/epoch=12-step=106144.ckpt', location='cuda'))\n",
    "# model.load_state_dict(load_state_dict('./lightning_logs/version_23786984/checkpoints/epoch=17-step=98531.ckpt', location='cuda'))\n",
    "\n",
    "model.load_state_dict(load_state_dict('./lightning_logs/version_'+version+'/checkpoints/epoch='+epoch+'-step='+step+'.ckpt', location='cpu'))\n",
    "#model.load_state_dict(load_state_dict('./version_archive/version_'+version+'_e'+epoch+'/checkpoints/epoch='+epoch+'-step='+step+'.ckpt', location='cpu'))\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae56cce3-1d8e-4233-9b8b-64a89a9f9054",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ddim_sampler = DDIMSampler(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6200814b-bb31-45e0-b53e-fee7093252b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee75bec-f240-4f43-bc3f-7ee7fc5d184b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24e12a4f-510c-434b-82b6-d2170835a50e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch is using GPU: 2\n",
      "GPU name: NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "# 检查 PyTorch 使用的设备\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"PyTorch is using GPU: {torch.cuda.current_device()}\")\n",
    "    print(f\"GPU name: {torch.cuda.get_device_name(torch.cuda.current_device())}\")\n",
    "else:\n",
    "    print(\"PyTorch is not using any GPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67882d6-1736-49b7-aa1a-235f63502c90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cef9c64c-82e0-4f3d-872d-8f86951da4d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dir_hemy = '/home/yuebing/Mingyi/GenerativeUrbanDesign/Urban_Data/'\n",
    "image_dir = '/home/yuebing/Mingyi/GenerativeUrbanDesign/Urban_Data/Vector_Image_Partition/'\n",
    "city = 'NewYork'\n",
    "data_dir = [dir_hemy + 'Descriptions/NewYork_grid_r0_d0.csv',\n",
    "            dir_hemy + 'Descriptions/NewYork_grid_r1_d0.csv',\n",
    "            dir_hemy + 'Descriptions/NewYork_grid_r2_d0.csv',\n",
    "            dir_hemy + 'Descriptions/NewYork_grid_r0_d1.csv',\n",
    "            dir_hemy + 'Descriptions/NewYork_grid_r1_d1.csv',\n",
    "            dir_hemy + 'Descriptions/NewYork_grid_r2_d1.csv',\n",
    "            dir_hemy + 'Descriptions/NewYork_grid_r0_d2.csv',\n",
    "            dir_hemy + 'Descriptions/NewYork_grid_r1_d2.csv',\n",
    "            dir_hemy + 'Descriptions/NewYork_grid_r2_d2.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94f79766-4ea6-42a2-a1df-bd7d4c88ac85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame() \n",
    "for f in data_dir: \n",
    "    dfi = pd.read_csv(f)\n",
    "    df = pd.concat([df, dfi[dfi['Train']==0]])\n",
    "\n",
    "#desc = {}\n",
    "#for c in ['NewYork']:\n",
    "    #desc[c] = pd.read_csv(\"~/satellite_tiles_control/tile_descriptions/tile_descriptions_\"+c+\"_1114.csv\").set_index(['xtile','ytile'])\n",
    "    #desc[c] = pd.read_csv(\"/home/yuebing/Mingyi/GenerativeUrbanDesign/Urban_Data/Descriptions/\"+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47d061eb-5861-422b-a0c9-cff6777cfff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "      <th>left_x</th>\n",
       "      <th>top_y</th>\n",
       "      <th>row</th>\n",
       "      <th>col</th>\n",
       "      <th>index_right</th>\n",
       "      <th>FID</th>\n",
       "      <th>r</th>\n",
       "      <th>d</th>\n",
       "      <th>fully_water_tag</th>\n",
       "      <th>...</th>\n",
       "      <th>lu_p_p</th>\n",
       "      <th>lu_mixed_p</th>\n",
       "      <th>lu_add</th>\n",
       "      <th>rd_pri_area</th>\n",
       "      <th>rd_pri_p</th>\n",
       "      <th>rd_res_p</th>\n",
       "      <th>rd_p</th>\n",
       "      <th>rd_category</th>\n",
       "      <th>descriptions</th>\n",
       "      <th>Train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>POLYGON ((279415.7200310936 38577.641927330675...</td>\n",
       "      <td>278965.720031</td>\n",
       "      <td>39027.641927</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>r0</td>\n",
       "      <td>d0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.806853</td>\n",
       "      <td>4418.146961</td>\n",
       "      <td>0.021818</td>\n",
       "      <td>0.046191</td>\n",
       "      <td>0.068009</td>\n",
       "      <td>low</td>\n",
       "      <td>Land use parcels include 37.5 percent of resid...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>POLYGON ((279865.7200310936 37677.641927330675...</td>\n",
       "      <td>279415.720031</td>\n",
       "      <td>38127.641927</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>r0</td>\n",
       "      <td>d0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3007.268568</td>\n",
       "      <td>0.014851</td>\n",
       "      <td>0.070089</td>\n",
       "      <td>0.084940</td>\n",
       "      <td>medium</td>\n",
       "      <td>Land use parcels include 100.0 percent of resi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>POLYGON ((279865.7200310936 38577.641927330675...</td>\n",
       "      <td>279415.720031</td>\n",
       "      <td>39027.641927</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>r0</td>\n",
       "      <td>d0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3150.531579</td>\n",
       "      <td>0.015558</td>\n",
       "      <td>0.084412</td>\n",
       "      <td>0.099970</td>\n",
       "      <td>medium</td>\n",
       "      <td>Land use parcels include 79.1 percent of resid...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>POLYGON ((279865.7200310936 40377.641927330675...</td>\n",
       "      <td>279415.720031</td>\n",
       "      <td>40827.641927</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>r0</td>\n",
       "      <td>d0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.768221</td>\n",
       "      <td>4318.422732</td>\n",
       "      <td>0.021326</td>\n",
       "      <td>0.035199</td>\n",
       "      <td>0.056525</td>\n",
       "      <td>low</td>\n",
       "      <td>Land use parcels include 30.4 percent of resid...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>POLYGON ((279865.7200310936 42177.641927330675...</td>\n",
       "      <td>279415.720031</td>\n",
       "      <td>42627.641927</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>r0</td>\n",
       "      <td>d0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.358653</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>low</td>\n",
       "      <td>Land use parcels include 0.0 percent of reside...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             geometry         left_x  \\\n",
       "9   POLYGON ((279415.7200310936 38577.641927330675...  278965.720031   \n",
       "15  POLYGON ((279865.7200310936 37677.641927330675...  279415.720031   \n",
       "17  POLYGON ((279865.7200310936 38577.641927330675...  279415.720031   \n",
       "21  POLYGON ((279865.7200310936 40377.641927330675...  279415.720031   \n",
       "25  POLYGON ((279865.7200310936 42177.641927330675...  279415.720031   \n",
       "\n",
       "           top_y  row  col  index_right  FID   r   d  fully_water_tag  ...  \\\n",
       "9   39027.641927    9    2            0    0  r0  d0                0  ...   \n",
       "15  38127.641927    7    3            0    0  r0  d0                0  ...   \n",
       "17  39027.641927    9    3            0    0  r0  d0                0  ...   \n",
       "21  40827.641927   13    3            0    0  r0  d0                0  ...   \n",
       "25  42627.641927   17    3            0    0  r0  d0                0  ...   \n",
       "\n",
       "    lu_p_p  lu_mixed_p    lu_add  rd_pri_area  rd_pri_p  rd_res_p      rd_p  \\\n",
       "9      0.0         0.0  0.806853  4418.146961  0.021818  0.046191  0.068009   \n",
       "15     0.0         0.0  1.000000  3007.268568  0.014851  0.070089  0.084940   \n",
       "17     0.0         0.0  1.000000  3150.531579  0.015558  0.084412  0.099970   \n",
       "21     0.0         0.0  0.768221  4318.422732  0.021326  0.035199  0.056525   \n",
       "25     0.0         0.0  0.358653     0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "    rd_category                                       descriptions  Train  \n",
       "9           low  Land use parcels include 37.5 percent of resid...      0  \n",
       "15       medium  Land use parcels include 100.0 percent of resi...      0  \n",
       "17       medium  Land use parcels include 79.1 percent of resid...      0  \n",
       "21          low  Land use parcels include 30.4 percent of resid...      0  \n",
       "25          low  Land use parcels include 0.0 percent of reside...      0  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b7c21cd-7b27-4ed9-8e8f-219793463fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs('./lightning_logs/version_'+version+'/image_log/', exist_ok=True)\n",
    "os.makedirs('./lightning_logs/version_'+version+'/image_output/', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc30eeb-0e19-4981-b0f8-1b19cf9e5951",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41944eaa-30e7-4b47-bd61-2881edd86e21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16c9c510-85fa-4f73-838f-382d2e03c6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_hemy = '/home/yuebing/Mingyi/GenerativeUrbanDesign/Urban_Data/'\n",
    "image_dir = dir_hemy + 'Vector_Image_Partition/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6be818d8-b61b-46b9-a13a-06b7c2fdc1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(xtile, ytile, r, d, zoom, input_city, output_city, prompt, a_prompt, n_prompt, num_samples, image_resolution, detect_resolution, ddim_steps, guess_mode, strength, scale, seed, eta, v=None, RGB=True):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        #input_image = cv2.imread(\"../satellite_tiles_control/satellite_tiles/\"+str(zoom)+\"/\"+input_city+\"/\"+str(zoom)+\"_\"+str(x)+\"_\"+str(y)+\".png\")\n",
    "        \n",
    "        #if right == 0:\n",
    "        #    if down == 0:\n",
    "        #        hint_name = image_dir + city + '_stage_1/' + str(xtile) + '_' + str(ytile) + '_' + str(xcord) + '_' + str(ycord) + '.tif'\n",
    "        #        img_name = image_dir + city + '_stage_2/' + str(xtile) + '_' + str(ytile) + '_' + str(xcord) + '_' + str(ycord) + '.tif'\n",
    "        #    elif down == 1:\n",
    "        #        hint_name = image_dir + city + '_stage_1_down/' + str(xtile) + '_' + str(ytile) + '_' + str(xcord) + '_' + str(ycord) + '.tif'\n",
    "        #        img_name = image_dir + city + '_stage_2_down/' + str(xtile) + '_' + str(ytile) + '_' + str(xcord) + '_' + str(ycord) + '.tif'\n",
    "        #elif right == 1:\n",
    "        #    if down == 0:\n",
    "        #        hint_name = image_dir + city + '_stage_1_right/' + str(xtile) + '_' + str(ytile) + '_' + str(xcord) + '_' + str(ycord) + '.tif'\n",
    "        #        img_name = image_dir + city + '_stage_2_right/' + str(xtile) + '_' + str(ytile) + '_' + str(xcord) + '_' + str(ycord) + '.tif'\n",
    "        #    elif down == 1:\n",
    "        #        hint_name = image_dir + city + '_stage_1_right_down/' + str(xtile) + '_' + str(ytile) + '_' + str(xcord) + '_' + str(ycord) + '.tif'\n",
    "        #        img_name = image_dir + city + '_stage_2_right_down/' + str(xtile) + '_' + str(ytile) + '_' + str(xcord) + '_' + str(ycord) + '.tif'  \n",
    "        #\n",
    "        \n",
    "        hint_name = image_dir + city + '_Stage_1_' + r + '_' + d + '/' + str(xtile) + '_' + str(ytile) + '_' + r + '_' + d + '.tif'\n",
    "        img_name =  image_dir + city + '_Stage_2_' + r + '_' + d + '/' + str(xtile) + '_' + str(ytile) + '_' + r + '_' + d + '.tif'     \n",
    "\n",
    "        input_image = cv2.imread(img_name)\n",
    "        input_image = np.array(input_image)\n",
    "        print(img_name)\n",
    "        H,W,C = input_image.shape\n",
    "\n",
    "        #if v is None:\n",
    "        #    detected_map = cv2.imread(\"../satellite_tiles_control/skeleton/\"+str(zoom)+\"/\"+input_city+\"/\"+str(x)+\"/\"+str(y)+\".png\", cv2.IMREAD_UNCHANGED)\n",
    "        #else:\n",
    "        #    detected_map = cv2.imread(\"../satellite_tiles_control/skeleton/\"+str(zoom)+\"/test/\"+str(x)+\"_\"+str(y)+\"_\"+v+\".png\", cv2.IMREAD_UNCHANGED)\n",
    "        \n",
    "        detected_map = cv2.imread(hint_name, cv2.IMREAD_UNCHANGED)\n",
    "        detected_map = np.array(detected_map)    \n",
    "        \n",
    "        if detected_map.shape[2] == 4:\n",
    "            # convert 4-channel source image to 3-channel\n",
    "            #make mask of where the transparent bits are\n",
    "            trans_mask = detected_map[:,:,3] == 0\n",
    "    \n",
    "            #replace areas of transparency with white and not transparent\n",
    "            detected_map[trans_mask] = [255, 255, 255, 255]\n",
    "    \n",
    "            #new image without alpha channel...\n",
    "            detected_map = cv2.cvtColor(detected_map, cv2.COLOR_BGRA2BGR)        \n",
    "        \n",
    "        #OpenCV read images in BGR order.\n",
    "        control = cv2.cvtColor(detected_map, cv2.COLOR_BGR2RGB)\n",
    "        control = torch.from_numpy(control.copy()).float().cuda() / 255.0\n",
    "        control = torch.stack([control for _ in range(num_samples)], dim=0)\n",
    "        control = einops.rearrange(control, 'b h w c -> b c h w').clone()\n",
    "\n",
    "        if seed == -1:\n",
    "            seed = random.randint(0, 65535)\n",
    "        seed_everything(seed)\n",
    "\n",
    "        if config.save_memory:\n",
    "            model.low_vram_shift(is_diffusing=False)\n",
    "            \n",
    "        cond = {\"c_concat\": [control], \"c_crossattn\": [model.get_learned_conditioning([prompt + ', ' + a_prompt] * num_samples)]}\n",
    "        un_cond = {\"c_concat\": None if guess_mode else [control], \"c_crossattn\": [model.get_learned_conditioning([n_prompt] * num_samples)]}\n",
    "        shape = (4, H // 8, W // 8)\n",
    "\n",
    "        if config.save_memory:\n",
    "            model.low_vram_shift(is_diffusing=True)\n",
    "\n",
    "        model.control_scales = [strength * (0.825 ** float(12 - i)) for i in range(13)] if guess_mode else ([strength] * 13)  # Magic number. IDK why. Perhaps because 0.825**12<0.01 but 0.826**12>0.01\n",
    "        samples, intermediates = ddim_sampler.sample(ddim_steps, num_samples,\n",
    "                                                     shape, cond, verbose=False, eta=eta,\n",
    "                                                     unconditional_guidance_scale=scale,\n",
    "                                                     unconditional_conditioning=un_cond)\n",
    "            \n",
    "        if config.save_memory:\n",
    "            model.low_vram_shift(is_diffusing=False)\n",
    "\n",
    "        x_samples = model.decode_first_stage(samples)\n",
    "        x_samples = (einops.rearrange(x_samples, 'b c h w -> b h w c') * 127.5 + 127.5).cpu().numpy().clip(0, 255).astype(np.uint8)\n",
    "\n",
    "        if RGB:\n",
    "            results = [x_samples[i] for i in range(num_samples)]\n",
    "            detected_map = cv2.cvtColor(detected_map, cv2.COLOR_BGR2RGB)\n",
    "        else:\n",
    "            results = [cv2.cvtColor(x_samples[i], cv2.COLOR_RGB2BGR) for i in range(num_samples)]\n",
    "\n",
    "        return [detected_map] + [input_image] + results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63da0695-9c34-4e06-96ab-87eeff59b97f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cad75ca6-3ba6-4da1-9829-35442b0962cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "zoom = \"16\"\n",
    "num_samples = 1\n",
    "image_resolution = 512\n",
    "strength = 1.0\n",
    "guess_mode = False\n",
    "detect_resolution = 512\n",
    "ddim_steps = 20\n",
    "scale = 9.0\n",
    "seed = 5354\n",
    "eta = 0.0\n",
    "a_prompt = 'best quality, extremely detailed'\n",
    "n_prompt = 'longbody, lowres, bad anatomy, bad hands, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188f9a69-7a0b-430d-a806-e922db50cb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da879dec-17ec-4833-9c2e-c221d884fbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_city = 'NewYork'\n",
    "output_city = 'NewYork'\n",
    "\n",
    "i = 0\n",
    "\n",
    "xtile = df.iloc[i]['row']\n",
    "ytile = df.iloc[i]['col']\n",
    "right = df.iloc[i]['r']\n",
    "down  = df.iloc[i]['d']\n",
    "\n",
    "prompt = df.iloc[i]['descriptions']\n",
    "#prompt = df.loc[(int(xtile),int(ytile))]['Land_use_description']\n",
    "\n",
    "RGB=True\n",
    "outputs0 = process(xtile, ytile, right, down, zoom, input_city, output_city, prompt, a_prompt, n_prompt, num_samples, image_resolution, detect_resolution, ddim_steps, guess_mode, strength, scale, seed, eta, v='0', RGB=RGB)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "176b305f-43d7-4511-b789-dab4ac14fb32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(outputs0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "27417cfe-5770-4302-bc91-91ca713bc6a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range(4873, 4874)\n",
      "range(2043, 2044)\n",
      "range(7119, 7120)\n",
      "range(740, 741)\n",
      "range(424, 425)\n",
      "range(3627, 3628)\n",
      "range(3270, 3271)\n",
      "range(2934, 2935)\n",
      "range(4604, 4605)\n",
      "range(694, 695)\n",
      "range(2859, 2860)\n",
      "range(7202, 7203)\n",
      "range(6899, 6900)\n",
      "range(6184, 6185)\n",
      "range(5304, 5305)\n",
      "range(6843, 6844)\n",
      "range(5619, 5620)\n",
      "range(801, 802)\n",
      "range(5881, 5882)\n",
      "range(7080, 7081)\n",
      "range(4391, 4392)\n",
      "range(292, 293)\n",
      "range(2845, 2846)\n",
      "range(3910, 3911)\n",
      "range(1979, 1980)\n",
      "range(5539, 5540)\n",
      "range(2195, 2196)\n",
      "range(2670, 2671)\n",
      "range(4959, 4960)\n",
      "range(1519, 1520)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "data = list(range(7354))\n",
    "\n",
    "# 随机选择30个不同的行号\n",
    "random_indices = random.sample(data, 30)\n",
    "\n",
    "selected_ranges = [range(index, index+1) for index in random_indices]\n",
    "\n",
    "# 打印结果\n",
    "for r in selected_ranges:\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41aa894e-5186-4062-ad70-6d7a5466fbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_indices = [\n",
    "3215,\n",
    "4139,\n",
    "9,\n",
    "3631,\n",
    "54,\n",
    "4805,\n",
    "3404,\n",
    "6939,\n",
    "7051,\n",
    "857,\n",
    "1070,\n",
    "6765,\n",
    "64,\n",
    "2534,\n",
    "7284,\n",
    "4908,\n",
    "6404,\n",
    "6611,\n",
    "5282,\n",
    "5820,\n",
    "5357,\n",
    "294,\n",
    "4840,\n",
    "1630,\n",
    "2616,\n",
    "3351,\n",
    "6560,\n",
    "5906,\n",
    "2720,\n",
    "5567]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b0d9d78-88fe-4cb0-836c-e142ee97bcd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "geometry           POLYGON ((316315.7200310936 53127.641927330675...\n",
       "left_x                                                 315865.720031\n",
       "top_y                                                   53577.641927\n",
       "row                                                               42\n",
       "col                                                               84\n",
       "index_right                                                        0\n",
       "FID                                                                0\n",
       "r                                                                 r0\n",
       "d                                                                 d2\n",
       "fully_water_tag                                                    0\n",
       "water_area                                                         0\n",
       "rd_m_area                                                        0.0\n",
       "rd_0_area                                                        0.0\n",
       "rd_1_area                                                        0.0\n",
       "rd_2_area                                                        0.0\n",
       "rd_3_area                                                        0.0\n",
       "rd_r_area                                                        0.0\n",
       "rd_m_l_area                                                      0.0\n",
       "rd_0_l_area                                                      0.0\n",
       "rd_1_l_area                                                      0.0\n",
       "rd_2_l_area                                                      0.0\n",
       "rd_3_l_area                                                      0.0\n",
       "lu_r_area                                                        0.0\n",
       "lu_c_area                                                        0.0\n",
       "lu_m_area                                                   202500.0\n",
       "lu_p_area                                                        0.0\n",
       "lu_mixed_area                                                    0.0\n",
       "grid_cell_area                                              202500.0\n",
       "lu_r_p                                                           0.0\n",
       "lu_c_p                                                           0.0\n",
       "lu_m_p                                                           1.0\n",
       "lu_p_p                                                           0.0\n",
       "lu_mixed_p                                                       0.0\n",
       "lu_add                                                           1.0\n",
       "rd_pri_area                                                      0.0\n",
       "rd_pri_p                                                         0.0\n",
       "rd_res_p                                                         0.0\n",
       "rd_p                                                             0.0\n",
       "rd_category                                                      low\n",
       "descriptions       Land use parcels include 0.0 percent of reside...\n",
       "Train                                                              0\n",
       "Name: 3337, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[5567]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0156e26a-59a2-4bd3-b6f6-39089d24ddd4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 5354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yuebing/Mingyi/GenerativeUrbanDesign/Urban_Data/Vector_Image_Partition/NewYork_Stage_2_r0_d1/70_99_r0_d1.tif\n",
      "Data shape for DDIM sampling is (1, 4, 64, 64), eta 0.0\n",
      "Running DDIM Sampling with 20 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|█████████████████████████████| 20/20 [00:07<00:00,  2.57it/s]\n",
      "Global seed set to 5354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yuebing/Mingyi/GenerativeUrbanDesign/Urban_Data/Vector_Image_Partition/NewYork_Stage_2_r2_d1/33_19_r2_d1.tif\n",
      "Data shape for DDIM sampling is (1, 4, 64, 64), eta 0.0\n",
      "Running DDIM Sampling with 20 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|█████████████████████████████| 20/20 [00:05<00:00,  3.77it/s]\n",
      "Global seed set to 5354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yuebing/Mingyi/GenerativeUrbanDesign/Urban_Data/Vector_Image_Partition/NewYork_Stage_2_r0_d0/8_5_r0_d0.tif\n",
      "Data shape for DDIM sampling is (1, 4, 64, 64), eta 0.0\n",
      "Running DDIM Sampling with 20 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|█████████████████████████████| 20/20 [00:04<00:00,  4.16it/s]\n",
      "Global seed set to 5354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yuebing/Mingyi/GenerativeUrbanDesign/Urban_Data/Vector_Image_Partition/NewYork_Stage_2_r1_d1/66_66_r1_d1.tif\n",
      "Data shape for DDIM sampling is (1, 4, 64, 64), eta 0.0\n",
      "Running DDIM Sampling with 20 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|█████████████████████████████| 20/20 [00:05<00:00,  3.74it/s]\n",
      "Global seed set to 5354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yuebing/Mingyi/GenerativeUrbanDesign/Urban_Data/Vector_Image_Partition/NewYork_Stage_2_r0_d0/34_14_r0_d0.tif\n",
      "Data shape for DDIM sampling is (1, 4, 64, 64), eta 0.0\n",
      "Running DDIM Sampling with 20 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|█████████████████████████████| 20/20 [00:05<00:00,  3.92it/s]\n",
      "Global seed set to 5354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yuebing/Mingyi/GenerativeUrbanDesign/Urban_Data/Vector_Image_Partition/NewYork_Stage_2_r2_d1/55_91_r2_d1.tif\n",
      "Data shape for DDIM sampling is (1, 4, 64, 64), eta 0.0\n",
      "Running DDIM Sampling with 20 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|█████████████████████████████| 20/20 [00:04<00:00,  4.08it/s]\n",
      "Global seed set to 5354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yuebing/Mingyi/GenerativeUrbanDesign/Urban_Data/Vector_Image_Partition/NewYork_Stage_2_r1_d1/51_49_r1_d1.tif\n",
      "Data shape for DDIM sampling is (1, 4, 64, 64), eta 0.0\n",
      "Running DDIM Sampling with 20 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|█████████████████████████████| 20/20 [00:05<00:00,  3.95it/s]\n",
      "Global seed set to 5354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yuebing/Mingyi/GenerativeUrbanDesign/Urban_Data/Vector_Image_Partition/NewYork_Stage_2_r2_d2/56_64_r2_d2.tif\n",
      "Data shape for DDIM sampling is (1, 4, 64, 64), eta 0.0\n",
      "Running DDIM Sampling with 20 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|█████████████████████████████| 20/20 [00:05<00:00,  3.89it/s]\n",
      "Global seed set to 5354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yuebing/Mingyi/GenerativeUrbanDesign/Urban_Data/Vector_Image_Partition/NewYork_Stage_2_r2_d2/69_70_r2_d2.tif\n",
      "Data shape for DDIM sampling is (1, 4, 64, 64), eta 0.0\n",
      "Running DDIM Sampling with 20 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|█████████████████████████████| 20/20 [00:05<00:00,  3.88it/s]\n",
      "Global seed set to 5354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yuebing/Mingyi/GenerativeUrbanDesign/Urban_Data/Vector_Image_Partition/NewYork_Stage_2_r1_d0/15_3_r1_d0.tif\n",
      "Data shape for DDIM sampling is (1, 4, 64, 64), eta 0.0\n",
      "Running DDIM Sampling with 20 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|█████████████████████████████| 20/20 [00:05<00:00,  3.90it/s]\n",
      "Global seed set to 5354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yuebing/Mingyi/GenerativeUrbanDesign/Urban_Data/Vector_Image_Partition/NewYork_Stage_2_r1_d0/52_51_r1_d0.tif\n",
      "Data shape for DDIM sampling is (1, 4, 64, 64), eta 0.0\n",
      "Running DDIM Sampling with 20 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|█████████████████████████████| 20/20 [00:04<00:00,  4.15it/s]\n",
      "Global seed set to 5354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yuebing/Mingyi/GenerativeUrbanDesign/Urban_Data/Vector_Image_Partition/NewYork_Stage_2_r2_d2/75_50_r2_d2.tif\n",
      "Data shape for DDIM sampling is (1, 4, 64, 64), eta 0.0\n",
      "Running DDIM Sampling with 20 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|█████████████████████████████| 20/20 [00:04<00:00,  4.34it/s]\n",
      "Global seed set to 5354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yuebing/Mingyi/GenerativeUrbanDesign/Urban_Data/Vector_Image_Partition/NewYork_Stage_2_r0_d0/25_16_r0_d0.tif\n",
      "Data shape for DDIM sampling is (1, 4, 64, 64), eta 0.0\n",
      "Running DDIM Sampling with 20 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|█████████████████████████████| 20/20 [00:05<00:00,  3.85it/s]\n",
      "Global seed set to 5354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yuebing/Mingyi/GenerativeUrbanDesign/Urban_Data/Vector_Image_Partition/NewYork_Stage_2_r0_d1/38_25_r0_d1.tif\n",
      "Data shape for DDIM sampling is (1, 4, 64, 64), eta 0.0\n",
      "Running DDIM Sampling with 20 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|█████████████████████████████| 20/20 [00:05<00:00,  3.97it/s]\n",
      "Global seed set to 5354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yuebing/Mingyi/GenerativeUrbanDesign/Urban_Data/Vector_Image_Partition/NewYork_Stage_2_r2_d2/93_90_r2_d2.tif\n",
      "Data shape for DDIM sampling is (1, 4, 64, 64), eta 0.0\n",
      "Running DDIM Sampling with 20 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|█████████████████████████████| 20/20 [00:05<00:00,  3.99it/s]\n",
      "Global seed set to 5354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yuebing/Mingyi/GenerativeUrbanDesign/Urban_Data/Vector_Image_Partition/NewYork_Stage_2_r0_d2/39_12_r0_d2.tif\n",
      "Data shape for DDIM sampling is (1, 4, 64, 64), eta 0.0\n",
      "Running DDIM Sampling with 20 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|█████████████████████████████| 20/20 [00:04<00:00,  4.12it/s]\n",
      "Global seed set to 5354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yuebing/Mingyi/GenerativeUrbanDesign/Urban_Data/Vector_Image_Partition/NewYork_Stage_2_r1_d2/77_84_r1_d2.tif\n",
      "Data shape for DDIM sampling is (1, 4, 64, 64), eta 0.0\n",
      "Running DDIM Sampling with 20 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|█████████████████████████████| 20/20 [00:05<00:00,  3.70it/s]\n",
      "Global seed set to 5354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yuebing/Mingyi/GenerativeUrbanDesign/Urban_Data/Vector_Image_Partition/NewYork_Stage_2_r2_d2/25_16_r2_d2.tif\n",
      "Data shape for DDIM sampling is (1, 4, 64, 64), eta 0.0\n",
      "Running DDIM Sampling with 20 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|█████████████████████████████| 20/20 [00:05<00:00,  3.92it/s]\n",
      "Global seed set to 5354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yuebing/Mingyi/GenerativeUrbanDesign/Urban_Data/Vector_Image_Partition/NewYork_Stage_2_r0_d2/88_65_r0_d2.tif\n",
      "Data shape for DDIM sampling is (1, 4, 64, 64), eta 0.0\n",
      "Running DDIM Sampling with 20 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|█████████████████████████████| 20/20 [00:04<00:00,  4.17it/s]\n",
      "Global seed set to 5354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yuebing/Mingyi/GenerativeUrbanDesign/Urban_Data/Vector_Image_Partition/NewYork_Stage_2_r1_d2/38_24_r1_d2.tif\n",
      "Data shape for DDIM sampling is (1, 4, 64, 64), eta 0.0\n",
      "Running DDIM Sampling with 20 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|█████████████████████████████| 20/20 [00:04<00:00,  4.24it/s]\n",
      "Global seed set to 5354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yuebing/Mingyi/GenerativeUrbanDesign/Urban_Data/Vector_Image_Partition/NewYork_Stage_2_r0_d2/79_69_r0_d2.tif\n",
      "Data shape for DDIM sampling is (1, 4, 64, 64), eta 0.0\n",
      "Running DDIM Sampling with 20 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|█████████████████████████████| 20/20 [00:05<00:00,  3.89it/s]\n",
      "Global seed set to 5354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yuebing/Mingyi/GenerativeUrbanDesign/Urban_Data/Vector_Image_Partition/NewYork_Stage_2_r0_d0/77_56_r0_d0.tif\n",
      "Data shape for DDIM sampling is (1, 4, 64, 64), eta 0.0\n",
      "Running DDIM Sampling with 20 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|█████████████████████████████| 20/20 [00:04<00:00,  4.10it/s]\n",
      "Global seed set to 5354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yuebing/Mingyi/GenerativeUrbanDesign/Urban_Data/Vector_Image_Partition/NewYork_Stage_2_r2_d1/49_95_r2_d1.tif\n",
      "Data shape for DDIM sampling is (1, 4, 64, 64), eta 0.0\n",
      "Running DDIM Sampling with 20 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|█████████████████████████████| 20/20 [00:05<00:00,  3.96it/s]\n",
      "Global seed set to 5354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yuebing/Mingyi/GenerativeUrbanDesign/Urban_Data/Vector_Image_Partition/NewYork_Stage_2_r1_d0/52_95_r1_d0.tif\n",
      "Data shape for DDIM sampling is (1, 4, 64, 64), eta 0.0\n",
      "Running DDIM Sampling with 20 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|█████████████████████████████| 20/20 [00:04<00:00,  4.25it/s]\n",
      "Global seed set to 5354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yuebing/Mingyi/GenerativeUrbanDesign/Urban_Data/Vector_Image_Partition/NewYork_Stage_2_r0_d1/41_50_r0_d1.tif\n",
      "Data shape for DDIM sampling is (1, 4, 64, 64), eta 0.0\n",
      "Running DDIM Sampling with 20 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|█████████████████████████████| 20/20 [00:05<00:00,  3.64it/s]\n",
      "Global seed set to 5354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yuebing/Mingyi/GenerativeUrbanDesign/Urban_Data/Vector_Image_Partition/NewYork_Stage_2_r1_d1/33_35_r1_d1.tif\n",
      "Data shape for DDIM sampling is (1, 4, 64, 64), eta 0.0\n",
      "Running DDIM Sampling with 20 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|█████████████████████████████| 20/20 [00:05<00:00,  3.93it/s]\n",
      "Global seed set to 5354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yuebing/Mingyi/GenerativeUrbanDesign/Urban_Data/Vector_Image_Partition/NewYork_Stage_2_r2_d2/17_3_r2_d2.tif\n",
      "Data shape for DDIM sampling is (1, 4, 64, 64), eta 0.0\n",
      "Running DDIM Sampling with 20 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|█████████████████████████████| 20/20 [00:05<00:00,  3.97it/s]\n",
      "Global seed set to 5354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yuebing/Mingyi/GenerativeUrbanDesign/Urban_Data/Vector_Image_Partition/NewYork_Stage_2_r1_d2/69_47_r1_d2.tif\n",
      "Data shape for DDIM sampling is (1, 4, 64, 64), eta 0.0\n",
      "Running DDIM Sampling with 20 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|█████████████████████████████| 20/20 [00:05<00:00,  3.86it/s]\n",
      "Global seed set to 5354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yuebing/Mingyi/GenerativeUrbanDesign/Urban_Data/Vector_Image_Partition/NewYork_Stage_2_r0_d1/56_59_r0_d1.tif\n",
      "Data shape for DDIM sampling is (1, 4, 64, 64), eta 0.0\n",
      "Running DDIM Sampling with 20 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|█████████████████████████████| 20/20 [00:04<00:00,  4.10it/s]\n",
      "Global seed set to 5354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yuebing/Mingyi/GenerativeUrbanDesign/Urban_Data/Vector_Image_Partition/NewYork_Stage_2_r0_d2/42_84_r0_d2.tif\n",
      "Data shape for DDIM sampling is (1, 4, 64, 64), eta 0.0\n",
      "Running DDIM Sampling with 20 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|█████████████████████████████| 20/20 [00:05<00:00,  3.87it/s]\n"
     ]
    }
   ],
   "source": [
    "input_city = 'NewYork'\n",
    "output_city = 'NewYork'\n",
    "outputs = []\n",
    "\n",
    "for i in random_indices:\n",
    "\n",
    "    xtile = df.iloc[i]['row']\n",
    "    ytile = df.iloc[i]['col']\n",
    "    right = df.iloc[i]['r']\n",
    "    down  = df.iloc[i]['d']\n",
    "    \n",
    "    prompt = df.iloc[i]['descriptions']\n",
    "    #prompt = df.loc[(int(xtile),int(ytile))]['Land_use_description']\n",
    "    \n",
    "    RGB=True\n",
    "    outputs_i = process(xtile, ytile, right, down, zoom, input_city, output_city, prompt, a_prompt, n_prompt, num_samples, image_resolution, detect_resolution, ddim_steps, guess_mode, strength, scale, seed, eta, v='0', RGB=RGB)\n",
    "    outputs.append(outputs_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eda8af8c-d80a-4471-8624-727e9f4e2fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_bgr_to_rgb(image):\n",
    "    \"\"\"\n",
    "    将 BGR 图像转换为 RGB 图像。\n",
    "    \"\"\"\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "50c31f30-9c0e-4adb-b2cc-3c750fd8928c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "output_file = './output_image/epoch_' + epoch\n",
    "os.makedirs(output_file, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ded9b603-baf8-4d53-91aa-e105dd462670",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(30):\n",
    "    i = random_indices[x]\n",
    "    xtile = df.iloc[i]['row']\n",
    "    ytile = df.iloc[i]['col']\n",
    "    right = df.iloc[i]['r']\n",
    "    down = df.iloc[i]['d']\n",
    "    \n",
    "    for y in range(3):        \n",
    "        if y ==2:\n",
    "            image = outputs[x][y]\n",
    "        \n",
    "            # Save each image with the desired naming convention\n",
    "            filename = f'{xtile}_{ytile}_{right}_{down}.png'\n",
    "            plt.imsave(os.path.join(output_file,filename), image)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e29b250-0f7f-44c1-b0b0-d2a8f38128b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(30,3, figsize=(6,72))\n",
    "#fig, ax = plt.subplots(5,3, figsize=(6,12))\n",
    "for x in range(30):\n",
    "    for y in range(3):\n",
    "        if y == 1:\n",
    "            ax[x,y].imshow(convert_bgr_to_rgb(outputs[x][y]))\n",
    "        else:\n",
    "            ax[x,y].imshow(outputs[x][y])\n",
    "\n",
    "for ax in ax.ravel():\n",
    "    ax.set_axis_off()\n",
    "#fig.savefig('output_image_e'+epoch+'.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b816eac-2d9c-479a-aec6-f068a9ebb262",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb56560-a79c-48a9-ad13-55eae4a7afc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "controlnet_hemy",
   "language": "python",
   "name": "controlnet_hemy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
